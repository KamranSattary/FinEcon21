{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nowcasting US GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kamran/anaconda3/lib/python3.7/site-packages/sqlalchemy/pool/base.py\", line 693, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/home/kamran/anaconda3/lib/python3.7/site-packages/sqlalchemy/pool/base.py\", line 880, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/home/kamran/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/default.py\", line 538, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL connection has been closed unexpectedly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fredapi import Fred\n",
    "import yaml\n",
    "import wrds\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "DATA_DIR = '../data/'\n",
    "OUTPUT_DIR = '../output/'\n",
    "\n",
    "with open(r'%sapi_key.yaml' %DATA_DIR) as file: \n",
    "    api_key = yaml.load(file, Loader=yaml.FullLoader)['api_key']\n",
    "    \n",
    "fred = Fred(api_key=api_key)\n",
    "\n",
    "db=wrds.Connection(wrds_username='kamransattary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_common_stocks = db.raw_sql(\"SELECT a.permno, a.date, b.shrcd, b.exchcd, a.ret, a.prc, a.shrout\"\n",
    "                                \" FROM crsp.msf AS a LEFT JOIN crsp.msenames as b\"\n",
    "                                \" ON a.permno=b.permno AND b.namedt<=a.date AND a.date<=b.nameendt\"\n",
    "                                \" WHERE b.shrcd in (10,11) AND b.exchcd in (1,2)\"\n",
    "                                \" AND a.date >='1980-01-01' AND a.date <='2019-12-31'\"\n",
    "                                )\n",
    "all_common_stocks['market_cap'] = np.abs(all_common_stocks['prc']) * all_common_stocks['shrout']\n",
    "\n",
    "def round_datetime(date):\n",
    "    '''round a given date to the first of the current month'''\n",
    "    return pd.to_datetime(str(date)[:7])\n",
    "all_common_stocks['date'] = all_common_stocks['date'].map(round_datetime)\n",
    "# top 20 market-cap stocks end of 2019\n",
    "top20 = all_common_stocks.loc[all_common_stocks['date']=='2019-12-01'].sort_values('market_cap', ascending=False)[:20].permno\n",
    "top20_ts = all_common_stocks.loc[all_common_stocks.permno.isin(top20)].pivot_table(values='ret', columns='permno', index='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_indicators = {'GDP':'earliest_available'}#, #GDP\n",
    "#                      'SP500':'1_month_lag', #SP500\n",
    "#                      'EXPGSC1':'earliest_available', #EXP G&S\n",
    "#                      'IMPGSC1':'earliest_available', #IMP G&S\n",
    "#                      'USAPFCEQDSMEI':'earliest_available', #Private Consumption\n",
    "#                      'DEXUSEU':'1_month_lag', #Exchange Rate USD EUR\n",
    "#                      'UNRATE':'earliest_available', #Unemployment \n",
    "#                      'LMJVTTUVUSM647S':'earliest_available', #Job vacancies\n",
    "#                      'PRS30006042':'earliest_available', #Manufacturing Sector: Real Output\n",
    "#                      'WM2NS':'1_month_lag', #M2 Money Stock (WM2NS)\n",
    "#                      'NASDAQ100':'1_month_lag', #NASDAQ 100 Index (NASDAQ100)\n",
    "#                      'RVXCLS':'1_month_lag', #CBOE Russell 2000 Volatility Index (RVXCLS)\n",
    "#                      'GFDEBTN':'earliest_available', #Federal Debt: Total Public Debt (GFDEBTN)\n",
    "#                      'NIKKEI225':'1_month_lag', #Nikkei Stock Average, Nikkei 225 (NIKKEI225)\n",
    "#                      'IRLTLT01USM156N':'1_month_lag', #Long-Term Government Bond Yields: 10-year: Main (Including Benchmark) for the United States (IRLTLT01USM156N)\n",
    "#                     }\n",
    "\n",
    "# \"\"\"\n",
    "# Dax - cant find\n",
    "# eurostoxx - cant find\n",
    "# ftse 100\n",
    "# hang seng\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(chosen_indicators, impute_method):\n",
    "    \n",
    "    final = top20_ts.copy()\n",
    "    for indicator in chosen_indicators.keys():\n",
    "        \n",
    "        if chosen_indicators[indicator] == 'earliest_available':\n",
    "            temp = fred.get_series_all_releases(indicator).dropna().sort_values('realtime_start')\n",
    "            temp = temp[~temp.date.dt.date.duplicated()]\n",
    "            temp = temp.loc[temp.realtime_start > '1999-12-01']\n",
    "            #temp['value'] = temp['value'].diff(periods=1) ## do we want to integrate first order?\n",
    "            temp['date'] = temp['date'].map(round_datetime)\n",
    "            temp = temp.set_index('date')\n",
    "            \n",
    "            if impute_method == 'sarimax':\n",
    "                data = np.asarray(temp.value).astype('float')\n",
    "\n",
    "                # Iterate over all ARMA(p,q) models with p,q in [0,6]\n",
    "                best_p, best_q = 0,0\n",
    "                best_aic = np.inf\n",
    "                for p in range(6):\n",
    "                    for q in range(6):\n",
    "                        if p == 0 and q == 0:\n",
    "                            continue\n",
    "\n",
    "                        # Estimate the model with missing datapoints\n",
    "                        mod = sm.tsa.statespace.SARIMAX(data, order=(p,0,q), enforce_invertibility=False)\n",
    "                        try:\n",
    "                            res = mod.fit(disp=False)\n",
    "                            if best_aic > res.aic and res.aic>0: \n",
    "                                best_p, best_q, best_aic = p, q, res.aic\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                mod = sm.tsa.statespace.SARIMAX(data, order=(best_p,0,best_q), enforce_invertibility=False)\n",
    "                res = mod.fit(disp=False)\n",
    "\n",
    "                # In-sample one-step-ahead predictions\n",
    "                predict = res.get_prediction(end=mod.nobs).predicted_mean\n",
    "                data[np.where(np.isnan(data))[0]] = predict[np.where(np.isnan(data))[0]].tolist()\n",
    "                data[0] = np.nan\n",
    "                temp['value'] = data[0:data.shape[0]]\n",
    "                \n",
    "            if impute_method == 'backfill':\n",
    "                temp = temp.resample('M').fillna(\"backfill\")\n",
    "                temp.index = temp.index.map(round_datetime)\n",
    "\n",
    "            if impute_method == 'linear_interpolate':\n",
    "                temp=temp.resample('M').first()\n",
    "                temp.index = temp.index.map(round_datetime)\n",
    "                temp['value'] = temp['value'].interpolate('linear')\n",
    "            \n",
    "            final = final.merge(temp['value'].to_frame(indicator), left_index=True, right_index=True, how='left')\n",
    "                        \n",
    "            if chosen_indicators[indicator] == '1_month_lag':\n",
    "                temp = fred.get_series(indicator).resample('M').mean().shift(1).dropna()\n",
    "                temp.index = temp.index.map(round_datetime)\n",
    "\n",
    "                final = final.merge(temp.to_frame(indicator), left_index=True, right_index=True)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = clean_data(chosen_indicators, impute_method='linear_interpolate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
